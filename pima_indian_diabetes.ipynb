{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pima_indian_diabetes.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"1Cd2opbxbROu","colab_type":"code","outputId":"201d0445-55ca-4be9-c22f-0d0d37b61fde","executionInfo":{"status":"ok","timestamp":1562058254945,"user_tz":-540,"elapsed":3835,"user":{"displayName":"이동재","photoUrl":"","userId":"12052501428717228434"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import auth\n","auth.authenticate_user()\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZGYjYzkZ26JG","colab_type":"code","outputId":"666a620a-951f-4ec9-ad98-a0f6dfc17c1b","executionInfo":{"status":"ok","timestamp":1562058257470,"user_tz":-540,"elapsed":924,"user":{"displayName":"이동재","photoUrl":"","userId":"12052501428717228434"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/gdrive/My Drive/colab"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/colab\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mL7zvImn9Fbf","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqpvhmwe3Y5G","colab_type":"code","outputId":"d82b6fab-132a-484f-e274-7f805be83209","executionInfo":{"status":"ok","timestamp":1562058530713,"user_tz":-540,"elapsed":877,"user":{"displayName":"이동재","photoUrl":"","userId":"12052501428717228434"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train = pd.read_excel('pima-indians-diabetes.train.xlsx')\n","test = pd.read_excel(\"pima-indians-diabetes.test.xlsx\")\n","train.shape"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(461, 9)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"t8pTzpUVcq9z","colab_type":"code","outputId":"f6d4f95b-36f9-4a7f-eddf-ef67301f6e4c","executionInfo":{"status":"ok","timestamp":1562058530714,"user_tz":-540,"elapsed":516,"user":{"displayName":"이동재","photoUrl":"","userId":"12052501428717228434"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test.shape"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(307, 9)"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"NSjRKJko-Dcv","colab_type":"code","outputId":"0e325a9e-d3d5-47a6-9df5-82990cb06120","executionInfo":{"status":"ok","timestamp":1562058531066,"user_tz":-540,"elapsed":569,"user":{"displayName":"이동재","photoUrl":"","userId":"12052501428717228434"}},"colab":{"base_uri":"https://localhost:8080/","height":140}},"source":["print(train.columns)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Index(['Number of times pregnant',\n","       'Plasma glucose concentration a 2 hours in an oral glucose tolerance test',\n","       'Diastolic blood pressure (mm Hg)', 'Triceps skin fold thickness (mm)',\n","       '2-Hour serum insulin (mu U/ml)',\n","       'Body mass index (weight in kg/(height in m)^2)',\n","       'Diabetes pedigree function', 'Age (years)', 'Class variable (0 or 1)'],\n","      dtype='object')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7VLAjJXm-xpB","colab_type":"code","outputId":"ec729c6a-a9cb-42d4-f774-0e1567be953f","executionInfo":{"status":"ok","timestamp":1562058536952,"user_tz":-540,"elapsed":5744,"user":{"displayName":"이동재","photoUrl":"","userId":"12052501428717228434"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["class_name = input(\"Chooese the class\")"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Chooese the classClass variable (0 or 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DgUHg4ED3uWO","colab_type":"code","colab":{}},"source":["minmax_scaler = MinMaxScaler()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6x0W2mAC-wgw","colab_type":"code","outputId":"a933e1c2-64cc-449e-cc01-a66b8b1b4a92","executionInfo":{"status":"ok","timestamp":1562058540201,"user_tz":-540,"elapsed":1164,"user":{"displayName":"이동재","photoUrl":"","userId":"12052501428717228434"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["tr_ans = train[class_name]\n","ts_ans = test[class_name]\n","class_count = len(tr_ans.unique())\n","print(class_count)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WnKjCuCfAguo","colab_type":"code","colab":{}},"source":["tr_data = train.drop([class_name], axis=1)\n","ts_data = test.drop([class_name], axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PktLBW6eQQHA","colab_type":"code","outputId":"bd812fb6-e200-4b7f-e7db-8963d54df798","executionInfo":{"status":"ok","timestamp":1562058544112,"user_tz":-540,"elapsed":747,"user":{"displayName":"이동재","photoUrl":"","userId":"12052501428717228434"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["ts_ans.dtype"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dtype('int64')"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"lmjXkka1Lucy","colab_type":"code","outputId":"7edc3aec-a0fa-4a33-d09b-1931e2d1fb27","executionInfo":{"status":"ok","timestamp":1562058547225,"user_tz":-540,"elapsed":723,"user":{"displayName":"이동재","photoUrl":"","userId":"12052501428717228434"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["from sklearn.preprocessing import Imputer\n","\n","rep_0 = Imputer(missing_values=0, strategy=\"mean\", axis=0)\n","\n","tr_data = rep_0.fit_transform(tr_data)\n","ts_data = rep_0.fit_transform(ts_data)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n","  warnings.warn(msg, category=DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Z_Yw0W7eAmgw","colab_type":"code","colab":{}},"source":["# tr_data = minmax_scaler.fit_transform(tr_data)\n","# ts_data = minmax_scaler.transform(ts_data)\n","tr_ans, _ = tr_ans.factorize()\n","ts_ans, _ = ts_ans.factorize()\n","tr_ans = np.array(tr_ans)\n","ts_ans = np.array(ts_ans)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rz4XG4MMOHGu","colab_type":"code","outputId":"70f5c169-28bc-4010-ae83-14209e83d278","executionInfo":{"status":"ok","timestamp":1562058552746,"user_tz":-540,"elapsed":712,"user":{"displayName":"이동재","photoUrl":"","userId":"12052501428717228434"}},"colab":{"base_uri":"https://localhost:8080/","height":386}},"source":["tr_ans"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n","       1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n","       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n","       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n","       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n","       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n","       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n","       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n","       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n","       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n","       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n","       1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n","       0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n","       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n","       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n","       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n","       0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n","       0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n","       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0])"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"wPJFAQ2X8C3R","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gTqMm-pu4GCy","colab_type":"code","colab":{}},"source":["import os\n","from datetime import datetime"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zh8cNr9S4Ju8","colab_type":"code","colab":{}},"source":["#about tensorboard\n","\n","# now = datetime.utcnow().strftime(\"&Y&m%d%H%M%S\")\n","# root_logdir = \"tf_logs\"\n","# logdir = \"{}/run-{}\".format(root_logdir, now)\n","# #%tensorboard --logdir logs\n","\n","# tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F0_cae6XOksE","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import ParameterGrid\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import Dropout\n","import tensorflow.keras.metrics as km\n","from sklearn import metrics\n","from tensorflow.keras.regularizers import l2\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8FW6kBo7uPs","colab_type":"code","colab":{}},"source":["from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import confusion_matrix\n","from functools import partial"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CHrsnp0Tq8CA","colab_type":"code","colab":{}},"source":["# real Version\n","\n","\n","# def create_model(hidden_layers = 1, neurons =1, init_mode = 'uniform', activation = 'elu'):\n","#   model = Sequential()\n","#   model.add(Dense(neurons, input_dim=len(tr_data.T), kernel_initializer=init_mode, activation=activation))\n","#   model.add(Dropout(0.2))\n","#   for i in range(hidden_layers):\n","    \n","#     model.add(Dense(neurons, kernel_initializer=init_mode))\n","#     model.add(BatchNormalization())\n","#     model.add(Activation(activation))\n","#     model.add(Dropout(0.2))\n","  \n","#   if class_count == 2:  \n","#     model.add(Dense(1,activation='sigmoid'))\n","#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","#   elif class_count != 2:\n","#     model.add(Dense(class_count-1, activation='softmax'))\n","#     model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","#   return model\n","\n","# keras_model = KerasClassifier(build_fn=create_model, epochs=32, batch_size=16)\n","# print(keras_model)\n","\n","\n","# leaky_relu = tf.nn.leaky_relu\n","# hidden_layers = [10,15,20]\n","# neurons = [30, 70, 110]\n","# activation = ['elu', leaky_relu]\n","# init_mode = ['glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n","\n","\n","# param_grid = dict(hidden_layers = hidden_layers, neurons = neurons, init_mode = init_mode, activation = activation)\n","# grid = GridSearchCV(estimator=keras_model, param_grid=param_grid, n_jobs= None, cv=2)\n","# print(grid)\n","\n","\n","\n","# grid_result = grid.fit(tr_data, tr_ans)\n","\n","# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","# means = grid_result.cv_results_['mean_test_score']\n","# stds = grid_result.cv_results_['std_test_score']\n","# params = grid_result.cv_results_['params']\n","\n","# for mean, stdev, param in zip(means, stds, params):\n","#     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n","\n","\n","# results = keras_model.predict(ts_data)\n","\n","# correct_count = (results == ts_ans).sum()\n","# accuracy = correct_count / len(ts_ans)\n","# ts_ans = ts_ans.astype(float)\n","# pred = pred.astype(float\n","# precision, recall, fbeta_score, support = precision_recall_fscore_support(ts_ans, results)\n","# conf_mat = confusion_matrix(ts_ans, results)\n","# print(\"Accuracy = \", accuracy)\n","# print(\"Precision = \", precision)\n","# print('Recall = ', recall)\n","# print(\"fbeta_score = \", fbeta_score)\n","# print(\"Support = \", support)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MKmXpPoXdidO","colab_type":"code","colab":{}},"source":["# testbed Version\n","\n","\n","def create_model():\n","  model = Sequential()\n","  model.add(Dense(len(tr_data.T), input_dim=len(tr_data.T), kernel_initializer='he_uniform',\n","                  activation='elu'))\n","  \n","  model.add(Dense(64, kernel_initializer='he_uniform'))\n","  model.add(BatchNormalization())\n","  model.add(Activation('elu'))\n","  model.add(Dropout(0.2))\n","  \n","  model.add(Dense(32, kernel_initializer='he_uniform'))\n","  model.add(BatchNormalization())\n","  model.add(Activation('elu'))\n","  model.add(Dropout(0.2))\n","  \n","  if class_count == 2:  \n","    model.add(Dense(1,activation='sigmoid'))\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  elif class_count != 2:\n","    model.add(Dense(class_count-1, activation='softmax'))\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wkbRQfalq0wM","colab_type":"code","outputId":"82f90e41-20f4-4c28-bcf4-73b77adc86f1","executionInfo":{"status":"ok","timestamp":1562058273140,"user_tz":-540,"elapsed":660,"user":{"displayName":"이동재","photoUrl":"","userId":"12052501428717228434"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["keras_model = KerasClassifier(build_fn=create_model, epochs=16, batch_size=8)\n","print(keras_model)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f8d14304940>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Th2q_eQEDcJ","colab_type":"code","outputId":"dcf722a0-225b-43c6-a8d6-e5099b859eb5","executionInfo":{"status":"ok","timestamp":1562058310452,"user_tz":-540,"elapsed":37749,"user":{"displayName":"이동재","photoUrl":"","userId":"12052501428717228434"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = KerasClassifier(build_fn=create_model, epochs=128, batch_size=8) \n","model.fit(tr_data, tr_ans)\n","tr_pred = model.predict(tr_data)\n","pred = model.predict(ts_data)\n","pred"],"execution_count":21,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0702 09:04:33.524669 140245270235008 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","W0702 09:04:33.566143 140245270235008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/128\n","461/461 [==============================] - 1s 2ms/sample - loss: 0.7736 - acc: 0.5553\n","Epoch 2/128\n","461/461 [==============================] - 0s 606us/sample - loss: 0.7378 - acc: 0.5748\n","Epoch 3/128\n","461/461 [==============================] - 0s 603us/sample - loss: 0.6387 - acc: 0.6529\n","Epoch 4/128\n","461/461 [==============================] - 0s 632us/sample - loss: 0.6221 - acc: 0.6638\n","Epoch 5/128\n","461/461 [==============================] - 0s 589us/sample - loss: 0.6185 - acc: 0.6638\n","Epoch 6/128\n","461/461 [==============================] - 0s 598us/sample - loss: 0.6217 - acc: 0.6746\n","Epoch 7/128\n","461/461 [==============================] - 0s 585us/sample - loss: 0.6016 - acc: 0.6725\n","Epoch 8/128\n","461/461 [==============================] - 0s 649us/sample - loss: 0.6066 - acc: 0.6876\n","Epoch 9/128\n","461/461 [==============================] - 0s 603us/sample - loss: 0.5727 - acc: 0.7007\n","Epoch 10/128\n","461/461 [==============================] - 0s 590us/sample - loss: 0.5696 - acc: 0.7137\n","Epoch 11/128\n","461/461 [==============================] - 0s 589us/sample - loss: 0.5836 - acc: 0.7007\n","Epoch 12/128\n","461/461 [==============================] - 0s 607us/sample - loss: 0.5691 - acc: 0.7050\n","Epoch 13/128\n","461/461 [==============================] - 0s 590us/sample - loss: 0.6052 - acc: 0.6768\n","Epoch 14/128\n","461/461 [==============================] - 0s 606us/sample - loss: 0.5538 - acc: 0.6963\n","Epoch 15/128\n","461/461 [==============================] - 0s 610us/sample - loss: 0.5785 - acc: 0.7223\n","Epoch 16/128\n","461/461 [==============================] - 0s 625us/sample - loss: 0.5642 - acc: 0.6963\n","Epoch 17/128\n","461/461 [==============================] - 0s 600us/sample - loss: 0.5767 - acc: 0.7028\n","Epoch 18/128\n","461/461 [==============================] - 0s 596us/sample - loss: 0.5386 - acc: 0.7397\n","Epoch 19/128\n","461/461 [==============================] - 0s 619us/sample - loss: 0.5705 - acc: 0.7115\n","Epoch 20/128\n","461/461 [==============================] - 0s 595us/sample - loss: 0.5585 - acc: 0.7354\n","Epoch 21/128\n","461/461 [==============================] - 0s 590us/sample - loss: 0.5463 - acc: 0.7245\n","Epoch 22/128\n","461/461 [==============================] - 0s 597us/sample - loss: 0.5631 - acc: 0.6963\n","Epoch 23/128\n","461/461 [==============================] - 0s 622us/sample - loss: 0.5693 - acc: 0.7180\n","Epoch 24/128\n","461/461 [==============================] - 0s 600us/sample - loss: 0.5606 - acc: 0.7267\n","Epoch 25/128\n","461/461 [==============================] - 0s 583us/sample - loss: 0.5379 - acc: 0.7332\n","Epoch 26/128\n","461/461 [==============================] - 0s 615us/sample - loss: 0.5384 - acc: 0.7050\n","Epoch 27/128\n","461/461 [==============================] - 0s 598us/sample - loss: 0.5144 - acc: 0.7440\n","Epoch 28/128\n","461/461 [==============================] - 0s 606us/sample - loss: 0.5437 - acc: 0.7245\n","Epoch 29/128\n","461/461 [==============================] - 0s 598us/sample - loss: 0.5533 - acc: 0.7072\n","Epoch 30/128\n","461/461 [==============================] - 0s 610us/sample - loss: 0.5496 - acc: 0.7289\n","Epoch 31/128\n","461/461 [==============================] - 0s 620us/sample - loss: 0.5299 - acc: 0.7289\n","Epoch 32/128\n","461/461 [==============================] - 0s 564us/sample - loss: 0.5259 - acc: 0.7375\n","Epoch 33/128\n","461/461 [==============================] - 0s 571us/sample - loss: 0.5224 - acc: 0.7223\n","Epoch 34/128\n","461/461 [==============================] - 0s 598us/sample - loss: 0.5275 - acc: 0.7440\n","Epoch 35/128\n","461/461 [==============================] - 0s 571us/sample - loss: 0.5211 - acc: 0.7267\n","Epoch 36/128\n","461/461 [==============================] - 0s 559us/sample - loss: 0.5320 - acc: 0.7267\n","Epoch 37/128\n","461/461 [==============================] - 0s 583us/sample - loss: 0.5328 - acc: 0.7202\n","Epoch 38/128\n","461/461 [==============================] - 0s 551us/sample - loss: 0.5300 - acc: 0.7223\n","Epoch 39/128\n","461/461 [==============================] - 0s 581us/sample - loss: 0.5483 - acc: 0.7332\n","Epoch 40/128\n","461/461 [==============================] - 0s 547us/sample - loss: 0.5257 - acc: 0.7093\n","Epoch 41/128\n","461/461 [==============================] - 0s 606us/sample - loss: 0.5355 - acc: 0.7289\n","Epoch 42/128\n","461/461 [==============================] - 0s 548us/sample - loss: 0.5300 - acc: 0.7289\n","Epoch 43/128\n","461/461 [==============================] - 0s 557us/sample - loss: 0.5620 - acc: 0.7223\n","Epoch 44/128\n","461/461 [==============================] - 0s 562us/sample - loss: 0.5219 - acc: 0.7354\n","Epoch 45/128\n","461/461 [==============================] - 0s 599us/sample - loss: 0.5415 - acc: 0.7419\n","Epoch 46/128\n","461/461 [==============================] - 0s 577us/sample - loss: 0.5468 - acc: 0.7158\n","Epoch 47/128\n","461/461 [==============================] - 0s 557us/sample - loss: 0.5286 - acc: 0.7354\n","Epoch 48/128\n","461/461 [==============================] - 0s 540us/sample - loss: 0.5389 - acc: 0.7050\n","Epoch 49/128\n","461/461 [==============================] - 0s 614us/sample - loss: 0.5289 - acc: 0.7332\n","Epoch 50/128\n","461/461 [==============================] - 0s 559us/sample - loss: 0.5457 - acc: 0.7223\n","Epoch 51/128\n","461/461 [==============================] - 0s 570us/sample - loss: 0.5336 - acc: 0.7462\n","Epoch 52/128\n","461/461 [==============================] - 0s 556us/sample - loss: 0.4934 - acc: 0.7397\n","Epoch 53/128\n","461/461 [==============================] - 0s 605us/sample - loss: 0.5165 - acc: 0.7549\n","Epoch 54/128\n","461/461 [==============================] - 0s 636us/sample - loss: 0.5321 - acc: 0.7375\n","Epoch 55/128\n","461/461 [==============================] - 0s 561us/sample - loss: 0.5552 - acc: 0.7158\n","Epoch 56/128\n","461/461 [==============================] - 0s 551us/sample - loss: 0.5265 - acc: 0.7267\n","Epoch 57/128\n","461/461 [==============================] - 0s 605us/sample - loss: 0.5408 - acc: 0.7180\n","Epoch 58/128\n","461/461 [==============================] - 0s 558us/sample - loss: 0.5101 - acc: 0.7375\n","Epoch 59/128\n","461/461 [==============================] - 0s 570us/sample - loss: 0.5171 - acc: 0.7549\n","Epoch 60/128\n","461/461 [==============================] - 0s 573us/sample - loss: 0.5249 - acc: 0.7332\n","Epoch 61/128\n","461/461 [==============================] - 0s 555us/sample - loss: 0.5097 - acc: 0.7484\n","Epoch 62/128\n","461/461 [==============================] - 0s 548us/sample - loss: 0.5188 - acc: 0.7375\n","Epoch 63/128\n","461/461 [==============================] - 0s 556us/sample - loss: 0.5321 - acc: 0.7115\n","Epoch 64/128\n","461/461 [==============================] - 0s 605us/sample - loss: 0.4997 - acc: 0.7505\n","Epoch 65/128\n","461/461 [==============================] - 0s 562us/sample - loss: 0.5063 - acc: 0.7289\n","Epoch 66/128\n","461/461 [==============================] - 0s 545us/sample - loss: 0.5443 - acc: 0.7223\n","Epoch 67/128\n","461/461 [==============================] - 0s 590us/sample - loss: 0.5300 - acc: 0.7462\n","Epoch 68/128\n","461/461 [==============================] - 0s 591us/sample - loss: 0.5167 - acc: 0.7375\n","Epoch 69/128\n","461/461 [==============================] - 0s 550us/sample - loss: 0.5330 - acc: 0.7115\n","Epoch 70/128\n","461/461 [==============================] - 0s 554us/sample - loss: 0.5150 - acc: 0.7462\n","Epoch 71/128\n","461/461 [==============================] - 0s 589us/sample - loss: 0.5055 - acc: 0.7570\n","Epoch 72/128\n","461/461 [==============================] - 0s 584us/sample - loss: 0.5238 - acc: 0.7354\n","Epoch 73/128\n","461/461 [==============================] - 0s 556us/sample - loss: 0.5132 - acc: 0.7505\n","Epoch 74/128\n","461/461 [==============================] - 0s 564us/sample - loss: 0.4946 - acc: 0.7592\n","Epoch 75/128\n","461/461 [==============================] - 0s 581us/sample - loss: 0.5073 - acc: 0.7505\n","Epoch 76/128\n","461/461 [==============================] - 0s 600us/sample - loss: 0.5123 - acc: 0.7440\n","Epoch 77/128\n","461/461 [==============================] - 0s 568us/sample - loss: 0.5229 - acc: 0.7462\n","Epoch 78/128\n","461/461 [==============================] - 0s 557us/sample - loss: 0.5058 - acc: 0.7462\n","Epoch 79/128\n","461/461 [==============================] - 0s 569us/sample - loss: 0.4967 - acc: 0.7527\n","Epoch 80/128\n","461/461 [==============================] - 0s 578us/sample - loss: 0.5079 - acc: 0.7505\n","Epoch 81/128\n","461/461 [==============================] - 0s 566us/sample - loss: 0.5050 - acc: 0.7397\n","Epoch 82/128\n","461/461 [==============================] - 0s 556us/sample - loss: 0.5154 - acc: 0.7354\n","Epoch 83/128\n","461/461 [==============================] - 0s 563us/sample - loss: 0.5073 - acc: 0.7527\n","Epoch 84/128\n","461/461 [==============================] - 0s 573us/sample - loss: 0.4860 - acc: 0.7332\n","Epoch 85/128\n","461/461 [==============================] - 0s 554us/sample - loss: 0.5124 - acc: 0.7332\n","Epoch 86/128\n","461/461 [==============================] - 0s 548us/sample - loss: 0.4926 - acc: 0.7505\n","Epoch 87/128\n","461/461 [==============================] - 0s 565us/sample - loss: 0.5260 - acc: 0.7440\n","Epoch 88/128\n","461/461 [==============================] - 0s 571us/sample - loss: 0.5388 - acc: 0.7462\n","Epoch 89/128\n","461/461 [==============================] - 0s 543us/sample - loss: 0.5026 - acc: 0.7419\n","Epoch 90/128\n","461/461 [==============================] - 0s 548us/sample - loss: 0.5181 - acc: 0.7527\n","Epoch 91/128\n","461/461 [==============================] - 0s 577us/sample - loss: 0.5019 - acc: 0.7375\n","Epoch 92/128\n","461/461 [==============================] - 0s 549us/sample - loss: 0.5256 - acc: 0.7354\n","Epoch 93/128\n","461/461 [==============================] - 0s 624us/sample - loss: 0.4998 - acc: 0.7375\n","Epoch 94/128\n","461/461 [==============================] - 0s 551us/sample - loss: 0.5157 - acc: 0.7419\n","Epoch 95/128\n","461/461 [==============================] - 0s 595us/sample - loss: 0.5036 - acc: 0.7592\n","Epoch 96/128\n","461/461 [==============================] - 0s 541us/sample - loss: 0.5192 - acc: 0.7462\n","Epoch 97/128\n","461/461 [==============================] - 0s 572us/sample - loss: 0.5206 - acc: 0.7505\n","Epoch 98/128\n","461/461 [==============================] - 0s 561us/sample - loss: 0.4925 - acc: 0.7614\n","Epoch 99/128\n","461/461 [==============================] - 0s 600us/sample - loss: 0.4955 - acc: 0.7527\n","Epoch 100/128\n","461/461 [==============================] - 0s 545us/sample - loss: 0.4825 - acc: 0.7549\n","Epoch 101/128\n","461/461 [==============================] - 0s 544us/sample - loss: 0.5135 - acc: 0.7592\n","Epoch 102/128\n","461/461 [==============================] - 0s 564us/sample - loss: 0.5031 - acc: 0.7484\n","Epoch 103/128\n","461/461 [==============================] - 0s 593us/sample - loss: 0.5202 - acc: 0.7440\n","Epoch 104/128\n","461/461 [==============================] - 0s 538us/sample - loss: 0.5194 - acc: 0.7375\n","Epoch 105/128\n","461/461 [==============================] - 0s 563us/sample - loss: 0.5086 - acc: 0.7462\n","Epoch 106/128\n","461/461 [==============================] - 0s 569us/sample - loss: 0.5050 - acc: 0.7375\n","Epoch 107/128\n","461/461 [==============================] - 0s 562us/sample - loss: 0.5100 - acc: 0.7592\n","Epoch 108/128\n","461/461 [==============================] - 0s 558us/sample - loss: 0.4956 - acc: 0.7657\n","Epoch 109/128\n","461/461 [==============================] - 0s 558us/sample - loss: 0.5312 - acc: 0.7180\n","Epoch 110/128\n","461/461 [==============================] - 0s 541us/sample - loss: 0.5124 - acc: 0.7549\n","Epoch 111/128\n","461/461 [==============================] - 0s 582us/sample - loss: 0.5074 - acc: 0.7549\n","Epoch 112/128\n","461/461 [==============================] - 0s 553us/sample - loss: 0.5154 - acc: 0.7462\n","Epoch 113/128\n","461/461 [==============================] - 0s 539us/sample - loss: 0.5068 - acc: 0.7440\n","Epoch 114/128\n","461/461 [==============================] - 0s 554us/sample - loss: 0.5056 - acc: 0.7570\n","Epoch 115/128\n","461/461 [==============================] - 0s 563us/sample - loss: 0.5019 - acc: 0.7484\n","Epoch 116/128\n","461/461 [==============================] - 0s 535us/sample - loss: 0.5190 - acc: 0.7332\n","Epoch 117/128\n","461/461 [==============================] - 0s 551us/sample - loss: 0.4796 - acc: 0.7614\n","Epoch 118/128\n","461/461 [==============================] - 0s 556us/sample - loss: 0.5092 - acc: 0.7397\n","Epoch 119/128\n","461/461 [==============================] - 0s 573us/sample - loss: 0.4893 - acc: 0.7679\n","Epoch 120/128\n","461/461 [==============================] - 0s 542us/sample - loss: 0.5144 - acc: 0.7462\n","Epoch 121/128\n","461/461 [==============================] - 0s 563us/sample - loss: 0.4849 - acc: 0.7744\n","Epoch 122/128\n","461/461 [==============================] - 0s 552us/sample - loss: 0.4811 - acc: 0.7722\n","Epoch 123/128\n","461/461 [==============================] - 0s 596us/sample - loss: 0.5115 - acc: 0.7419\n","Epoch 124/128\n","461/461 [==============================] - 0s 540us/sample - loss: 0.4874 - acc: 0.7614\n","Epoch 125/128\n","461/461 [==============================] - 0s 556us/sample - loss: 0.4884 - acc: 0.7527\n","Epoch 126/128\n","461/461 [==============================] - 0s 548us/sample - loss: 0.4962 - acc: 0.7375\n","Epoch 127/128\n","461/461 [==============================] - 0s 575us/sample - loss: 0.5122 - acc: 0.7419\n","Epoch 128/128\n","461/461 [==============================] - 0s 552us/sample - loss: 0.5286 - acc: 0.7397\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [0],\n","       [1],\n","       [0],\n","       [1],\n","       [0],\n","       [0],\n","       [1],\n","       [1],\n","       [1],\n","       [0],\n","       [0]])"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"1kjIJtK8U9el","colab_type":"code","outputId":"e8427b91-6522-4b93-c570-3d660d9e72a8","executionInfo":{"status":"ok","timestamp":1562058310454,"user_tz":-540,"elapsed":36663,"user":{"displayName":"이동재","photoUrl":"","userId":"12052501428717228434"}},"colab":{"base_uri":"https://localhost:8080/","height":281}},"source":["accuracy = accuracy_score(pred, ts_ans)\n","ts_ans = ts_ans.astype(float)\n","precision, recall, fbeta_score, support = precision_recall_fscore_support(ts_ans, pred)\n","conf_mat = confusion_matrix(ts_ans, pred)\n","print(\"Accuracy = \", accuracy)\n","print(\"Confusion Matrix\")\n","print(\"{0}\".format(metrics.confusion_matrix(ts_ans, pred)))\n","print(\"\")\n","print(\"Classification Report\")\n","print(metrics.classification_report(ts_ans, pred))\n","\n","\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Accuracy =  0.7817589576547231\n","Confusion Matrix\n","[[174  36]\n"," [ 31  66]]\n","\n","Classification Report\n","              precision    recall  f1-score   support\n","\n","         0.0       0.85      0.83      0.84       210\n","         1.0       0.65      0.68      0.66        97\n","\n","    accuracy                           0.78       307\n","   macro avg       0.75      0.75      0.75       307\n","weighted avg       0.79      0.78      0.78       307\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1pNmP5gQVTsZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}